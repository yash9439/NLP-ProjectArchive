{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-04-17T10:13:46.950341Z","iopub.execute_input":"2023-04-17T10:13:46.951241Z","iopub.status.idle":"2023-04-17T10:13:47.044864Z","shell.execute_reply.started":"2023-04-17T10:13:46.951199Z","shell.execute_reply":"2023-04-17T10:13:47.043719Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/savedbidafmodel/charwidth4.pth\n/kaggle/input/savedbidafmodel/AdaDelta_halved_5epochs.pth\n/kaggle/input/savedbidafmodel/Adam_default.pth\n/kaggle/input/savedbidafmodel/AdaDelta_halved.pth\n/kaggle/input/savedbidafmodel/dropout-.25.pth\n/kaggle/input/savedbidafmodel/AdaDelta_default.pth\n/kaggle/input/savedbidafmodel/hidden50.pth\n/kaggle/input/savedbidafmodel/AdaDelta_doubled.pth\n/kaggle/input/savedbidafmodel/dropout-.15.pth\n/kaggle/input/savedbidafmodel/SGD_default.pth\n/kaggle/input/new-squaddataset/train-v2.0.json\n/kaggle/input/new-squaddataset/dev-v2.0.json\n/kaggle/input/loadbidaf/bidaftrain.pkl\n/kaggle/input/loadbidaf/bidafw2id.pickle\n/kaggle/input/loadbidaf/bidafc2id.pickle\n/kaggle/input/loadbidaf/bidafglove_tv.npy\n/kaggle/input/loadbidaf/bidafvalid.pkl\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocess ","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport re, os, string, typing, gc, json\nimport spacy\nfrom collections import Counter\nnlp = spacy.blank('en')\n\n\ndef load_json(path):\n    '''\n    Loads the JSON file of the Squad dataset.\n    Returns the json object of the dataset.\n    '''\n    with open(path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n        \n    print(\"Length of data: \", len(data['data']))\n    print(\"Data Keys: \", data['data'][0].keys())\n    print(\"Title: \", data['data'][0]['title'])\n    \n    return data\n\n\n\ndef parse_data(data:dict)->list:\n    '''\n    Parses the JSON file of Squad dataset by looping through the\n    keys and values and returns a list of dictionaries with\n    context, query and label triplets being the keys of each dict.\n    '''\n    data = data['data']\n    qa_list = []\n\n    for paragraphs in data:\n\n        for para in paragraphs['paragraphs']:\n            context = para['context']\n\n            for qa in para['qas']:\n                \n                id = qa['id']\n                question = qa['question']\n                \n                for ans in qa['answers']:\n                    answer = ans['text']\n                    ans_start = ans['answer_start']\n                    ans_end = ans_start + len(answer)\n                    \n                    qa_dict = {}\n                    qa_dict['id'] = id\n                    qa_dict['context'] = context\n                    qa_dict['question'] = question\n                    qa_dict['label'] = [ans_start, ans_end]\n\n                    qa_dict['answer'] = answer\n                    qa_list.append(qa_dict)    \n\n    \n    return qa_list\n\n\n\ndef filter_large_examples(df):\n    '''\n    Returns ids of examples where context lengths, query lengths and answer lengths are\n    above a particular threshold. These ids can then be dropped from the dataframe. \n    This is explicitly mentioned in QANet but can be done for other models as well.\n    '''\n    \n    ctx_lens = []\n    query_lens = []\n    ans_lens = []\n    for index, row in df.iterrows():\n        ctx_tokens = [w.text for w in nlp(row.context, disable=['parser','ner','tagger'])]\n        if len(ctx_tokens)>400:\n            ctx_lens.append(row.name)\n\n        query_tokens = [w.text for w in nlp(row.question, disable=['parser','tagger','ner'])]\n        if len(query_tokens)>50:\n            query_lens.append(row.name)\n\n        ans_tokens = [w.text for w in nlp(row.answer, disable=['parser','tagger','ner'])]\n        if len(ans_tokens)>30:\n            ans_lens.append(row.name)\n\n        assert row.name == index\n    \n    return set(ans_lens + ctx_lens + query_lens)\n\n\ndef gather_text_for_vocab(dfs:list):\n    '''\n    Gathers text from contexts and questions to build a vocabulary.\n    \n    :param dfs: list of dataframes of SQUAD dataset.\n    :returns: list of contexts and questions\n    '''\n    \n    text = []\n    total = 0\n    for df in dfs:\n        unique_contexts = list(df.context.unique())\n        unique_questions = list(df.question.unique())\n        total += df.context.nunique() + df.question.nunique()\n        text.extend(unique_contexts + unique_questions)\n    \n    assert len(text) == total\n    \n    return text\n\n\n\n\ndef build_word_vocab(vocab_text):\n    '''\n    Builds a word-level vocabulary from the given text.\n    \n    :param list vocab_text: list of contexts and questions\n    :returns \n        dict word2idx: word to index mapping of words\n        dict idx2word: integer to word mapping\n        list word_vocab: list of words sorted by frequency\n    '''\n    \n    \n    words = []\n    for sent in vocab_text:\n        for word in nlp(sent, disable=['parser','tagger','ner']):\n            words.append(word.text)\n\n    word_counter = Counter(words)\n    word_vocab = sorted(word_counter, key=word_counter.get, reverse=True)\n    print(f\"raw-vocab: {len(word_vocab)}\")\n    word_vocab.insert(0, '<unk>')\n    word_vocab.insert(1, '<pad>')\n    print(f\"vocab-length: {len(word_vocab)}\")\n    word2idx = {word:idx for idx, word in enumerate(word_vocab)}\n    print(f\"word2idx-length: {len(word2idx)}\")\n    idx2word = {v:k for k,v in word2idx.items()}\n    \n    \n    return word2idx, idx2word, word_vocab\n\n\n\n\n\ndef build_char_vocab(vocab_text):\n    '''\n    Builds a character-level vocabulary from the given text.\n    \n    :param list vocab_text: list of contexts and questions\n    :returns \n        dict char2idx: character to index mapping of words\n        list char_vocab: list of characters sorted by frequency\n    '''\n    \n    chars = []\n    for sent in vocab_text:\n        for ch in sent:\n            chars.append(ch)\n\n    char_counter = Counter(chars)\n    char_vocab = sorted(char_counter, key=char_counter.get, reverse=True)\n    print(f\"raw-char-vocab: {len(char_vocab)}\")\n    high_freq_char = [char for char, count in char_counter.items() if count>=20]\n    char_vocab = list(set(char_vocab).intersection(set(high_freq_char)))\n    print(f\"char-vocab-intersect: {len(char_vocab)}\")\n    char_vocab.insert(0,'<unk>')\n    char_vocab.insert(1,'<pad>')\n    char2idx = {char:idx for idx, char in enumerate(char_vocab)}\n    print(f\"char2idx-length: {len(char2idx)}\")\n    \n    return char2idx, char_vocab\n\n\n\ndef context_to_ids(text, word2idx):\n    '''\n    Converts context text to their respective ids by mapping each word\n    using word2idx. Input text is tokenized using spacy tokenizer first.\n    \n    :param str text: context text to be converted\n    :param dict word2idx: word to id mapping\n\n    :returns list context_ids: list of mapped ids\n    \n    :raises assertion error: sanity check\n    \n    '''\n    \n    context_tokens = [w.text for w in nlp(text, disable=['parser','tagger','ner'])]\n    context_ids = [word2idx[word] for word in context_tokens]\n    \n    assert len(context_ids) == len(context_tokens)\n    return context_ids\n\n\n\n    \ndef question_to_ids(text, word2idx):\n    '''\n    Converts question text to their respective ids by mapping each word\n    using word2idx. Input text is tokenized using spacy tokenizer first.\n    \n    :param str text: question text to be converted\n    :param dict word2idx: word to id mapping\n    :returns list context_ids: list of mapped ids\n    \n    :raises assertion error: sanity check\n    \n    '''\n    \n    question_tokens = [w.text for w in nlp(text, disable=['parser','tagger','ner'])]\n    question_ids = [word2idx[word] for word in question_tokens]\n    \n    assert len(question_ids) == len(question_tokens)\n    return question_ids\n    \n\n\n    \ndef test_indices(df, idx2word):\n    '''\n    Performs the tests mentioned above. This method also gets the start and end of the answers\n    with respect to the context_ids for each example.\n    \n    :param dataframe df: SQUAD df\n    :param dict idx2word: inverse mapping of token ids to words\n    :returns\n        list start_value_error: example idx where the start idx is not found in the start spans\n                                of the text\n        list end_value_error: example idx where the end idx is not found in the end spans\n                              of the text\n        list assert_error: examples that fail assertion errors. A majority are due to the above errors\n        \n    '''\n\n    start_value_error = []\n    end_value_error = []\n    assert_error = []\n    for index, row in df.iterrows():\n\n        answer_tokens = [w.text for w in nlp(row['answer'], disable=['parser','tagger','ner'])]\n\n        start_token = answer_tokens[0]\n        end_token = answer_tokens[-1]\n        \n        context_span  = [(word.idx, word.idx + len(word.text)) \n                         for word in nlp(row['context'], disable=['parser','tagger','ner'])]\n\n        starts, ends = zip(*context_span)\n\n        answer_start, answer_end = row['label']\n\n        try:\n            start_idx = starts.index(answer_start)\n        except:\n            start_value_error.append(index)\n        try:\n            end_idx  = ends.index(answer_end)\n        except:\n            end_value_error.append(index)\n\n        try:\n            assert idx2word[row['context_ids'][start_idx]] == answer_tokens[0]\n            assert idx2word[row['context_ids'][end_idx]] == answer_tokens[-1]\n        except:\n            assert_error.append(index)\n\n\n    return start_value_error, end_value_error, assert_error\n\n\n\ndef get_error_indices(df, idx2word):\n    \n    start_value_error, end_value_error, assert_error = test_indices(df, idx2word)\n    err_idx = start_value_error + end_value_error + assert_error\n    err_idx = set(err_idx)\n    print(f\"Number of error indices: {len(err_idx)}\")\n    \n    return err_idx\n\n\n\ndef index_answer(row, idx2word):\n    '''\n    Takes in a row of the dataframe or one training example and\n    returns a tuple of start and end positions of answer by calculating \n    spans.\n    '''\n    \n    context_span = [(word.idx, word.idx + len(word.text)) for word in nlp(row.context, disable=['parser','tagger','ner'])]\n    starts, ends = zip(*context_span)\n    \n    answer_start, answer_end = row.label\n    start_idx = starts.index(answer_start)\n \n    end_idx  = ends.index(answer_end)\n    \n    ans_toks = [w.text for w in nlp(row.answer,disable=['parser','tagger','ner'])]\n    ans_start = ans_toks[0]\n    ans_end = ans_toks[-1]\n    assert idx2word[row.context_ids[start_idx]] == ans_start\n    assert idx2word[row.context_ids[end_idx]] == ans_end\n    \n    return [start_idx, end_idx]\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T18:38:04.420653Z","iopub.execute_input":"2023-04-17T18:38:04.421094Z","iopub.status.idle":"2023-04-17T18:38:46.389363Z","shell.execute_reply.started":"2023-04-17T18:38:04.421059Z","shell.execute_reply":"2023-04-17T18:38:46.388127Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## BiDAF (Bi-Directional Attention Flow)\n\n## Goal: Maximize the EM and F1 score to the SQuAD dataset by finetuning the existing BiDAF hyperparameter settings.\n","metadata":{}},{"cell_type":"markdown","source":"First, we will test learning rate and optimizer individually as they are relatively isolated from other variables but very close to each other.","metadata":{"id":"GBSRdaZSXFj6"}},{"cell_type":"markdown","source":"While the original batch size was 16, we were forced to decrease it to 8 due to the limited amount of computation resources. A higher batch size would cause the runtime to be out of memory, therefore making the training impossible. Moreover, a smaller batch size would also help the model to achieve a better performance when finetuning.","metadata":{}},{"cell_type":"markdown","source":"Now, we have determined that AdaDelta with learning rate of 0.5 works best for this model with a F1 score of over 55 and EM score of over 67 after 3 epochs. We will then move onto batch size, which is also very much separated from other parameters.\n\nNote: model_name will be overwritten here. Please assume the optimizer and learning rate picked is the configuration with the best overall performance.","metadata":{}},{"cell_type":"markdown","source":"Note: A 0.15 dropout rate actually performed better under default AdaDelta learning rate, and was thus used in the experiments of the subsequent hyperparameters. However, the final model excluded such choice as the performance of it peaked at the second epoch instead of the last epoch as expected.  Hence, we decided that making the dropout rate 0.2 would be more favorable when we train 2 more epochs ","metadata":{}},{"cell_type":"markdown","source":"After testing all of the configurations above, the final model was decided (the configurations above). We decided to train it to 5 epochs to observe if it was improved. The state dictionary, loss, EM, F1 of each experiment can be found under [model_name].pth inside the results folder.","metadata":{"id":"pwxVcVxtXFj-"}},{"cell_type":"code","source":"!pip install spacy","metadata":{"id":"r4Iuuk4pXFj_","outputId":"a0bdc108-51c8-47f2-81dc-ed7e2977d745","execution":{"iopub.status.busy":"2023-04-17T10:14:28.326216Z","iopub.execute_input":"2023-04-17T10:14:28.326910Z","iopub.status.idle":"2023-04-17T10:14:39.744122Z","shell.execute_reply.started":"2023-04-17T10:14:28.326874Z","shell.execute_reply":"2023-04-17T10:14:39.742873Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (3.5.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.28.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy) (8.1.9)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.4.6)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.9)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.21.6)\nRequirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.4.0)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.1.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.10.4)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.4)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (6.3.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.64.1)\nRequirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.7.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (23.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.8)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.7)\nRequirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.10.1)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.3.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (59.8.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy) (2.1.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy) (4.11.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from torch import nn\nimport torch\nimport numpy as np\nimport pandas as pd\nimport pickle, time\nimport re, os, string, typing, gc, json\nimport torch.nn.functional as F\nimport spacy\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nnlp = spacy.blank('en')\n%load_ext autoreload\n%autoreload 2","metadata":{"id":"Ksi8JbYgXFkA","outputId":"e226928b-20d8-48aa-92f9-6d9c6898f34c","execution":{"iopub.status.busy":"2023-04-17T10:14:39.747315Z","iopub.execute_input":"2023-04-17T10:14:39.747798Z","iopub.status.idle":"2023-04-17T10:14:40.169794Z","shell.execute_reply.started":"2023-04-17T10:14:39.747745Z","shell.execute_reply":"2023-04-17T10:14:40.168696Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data Preprocessing","metadata":{"id":"6WzJf3DhXFkA"}},{"cell_type":"markdown","source":"Please make sure you have downloaded the SQuAD dataset JSON files and stored them under /data before proceeding.","metadata":{}},{"cell_type":"code","source":"# load data from pickle files\n\ntrain_df = pd.read_pickle('/kaggle/input/loadbidaf/bidaftrain.pkl')\nvalid_df = pd.read_pickle('/kaggle/input/loadbidaf/bidafvalid.pkl')\n\nwith open('/kaggle/input/loadbidaf/bidafw2id.pickle','rb') as handle:\n    word2idx = pickle.load(handle)\nwith open('/kaggle/input/loadbidaf/bidafc2id.pickle','rb') as handle:\n    char2idx = pickle.load(handle)\n\nidx2word = {v:k for k,v in word2idx.items()}","metadata":{"id":"XGwDCpU4XFkD","execution":{"iopub.status.busy":"2023-04-17T10:14:40.172967Z","iopub.execute_input":"2023-04-17T10:14:40.173328Z","iopub.status.idle":"2023-04-17T10:14:45.055259Z","shell.execute_reply.started":"2023-04-17T10:14:40.173291Z","shell.execute_reply":"2023-04-17T10:14:45.054154Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader/Dataset","metadata":{"id":"WCyvgNQRXFkD"}},{"cell_type":"code","source":"class SquadDataset:\n    '''\n    - Creates batches dynamically by padding to the length of largest example\n      in a given batch.\n    - Calulates character vectors for contexts and question.\n    - Returns tensors for training.\n    '''\n    \n    def __init__(self, data, batch_size):\n        \n        self.batch_size = batch_size\n        data = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n        self.data = data\n        \n        \n    def __len__(self):\n        return len(self.data)\n    \n    def make_char_vector(self, max_sent_len, max_word_len, sentence):\n        \n        char_vec = torch.ones(max_sent_len, max_word_len).type(torch.LongTensor)\n        \n        for i, word in enumerate(nlp(sentence, disable=['parser','tagger','ner',\"lemmatizer\"])):\n            for j, ch in enumerate(word.text):\n                char_vec[i][j] = char2idx.get(ch, 0)\n        \n        return char_vec    \n    \n    def get_span(self, text):\n        \n        text = nlp(text, disable=['parser','tagger','ner'])\n        span = [(w.idx, w.idx+len(w.text)) for w in text]\n\n        return span\n\n    def __iter__(self):\n        '''\n        Creates batches of data and yields them.\n        \n        Each yield comprises of:\n        :padded_context: padded tensor of contexts for each batch \n        :padded_question: padded tensor of questions for each batch \n        :char_ctx & ques_ctx: character-level ids for context and question\n        :label: start and end index wrt context_ids\n        :context_text,answer_text: used while validation to calculate metrics\n        :ids: question_ids for evaluation\n        \n        '''\n        \n        for batch in self.data:\n            \n            spans = []\n            ctx_text = []\n            answer_text = []\n            \n            for ctx in batch.context:\n                ctx_text.append(ctx)\n                spans.append(self.get_span(ctx))\n            \n            for ans in batch.answer:\n                answer_text.append(ans)\n                \n            \n            max_context_len = max([len(ctx) for ctx in batch.context_ids])\n            padded_context = torch.LongTensor(len(batch), max_context_len).fill_(1)\n            \n            for i, ctx in enumerate(batch.context_ids):\n                padded_context[i, :len(ctx)] = torch.LongTensor(ctx)\n                \n            max_word_ctx = 0\n            for context in batch.context:\n                for word in nlp(context, disable=['parser','tagger','ner']):\n                    if len(word.text) > max_word_ctx:\n                        max_word_ctx = len(word.text)\n            \n            char_ctx = torch.ones(len(batch), max_context_len, max_word_ctx).type(torch.LongTensor)\n            for i, context in enumerate(batch.context):\n                char_ctx[i] = self.make_char_vector(max_context_len, max_word_ctx, context)\n            \n            max_question_len = max([len(ques) for ques in batch.question_ids])\n            padded_question = torch.LongTensor(len(batch), max_question_len).fill_(1)\n            \n            for i, ques in enumerate(batch.question_ids):\n                padded_question[i, :len(ques)] = torch.LongTensor(ques)\n                \n            max_word_ques = 0\n            for question in batch.question:\n                for word in nlp(question, disable=['parser','tagger','ner']):\n                    if len(word.text) > max_word_ques:\n                        max_word_ques = len(word.text)\n            \n            char_ques = torch.ones(len(batch), max_question_len, max_word_ques).type(torch.LongTensor)\n            for i, question in enumerate(batch.question):\n                char_ques[i] = self.make_char_vector(max_question_len, max_word_ques, question)\n            \n            ids = list(batch.id)  \n            label = torch.LongTensor(list(batch.label_idx))\n            \n            yield (padded_context, padded_question, char_ctx, char_ques, label, ctx_text, answer_text, ids)\n            \n            ","metadata":{"id":"sOG5DK_JXFkD","execution":{"iopub.status.busy":"2023-04-17T10:14:45.057776Z","iopub.execute_input":"2023-04-17T10:14:45.058597Z","iopub.status.idle":"2023-04-17T10:14:45.147463Z","shell.execute_reply.started":"2023-04-17T10:14:45.058536Z","shell.execute_reply":"2023-04-17T10:14:45.146496Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8\ntrain_dataset = SquadDataset(train_df, BATCH_SIZE)","metadata":{"id":"15GFX63MXFkF","execution":{"iopub.status.busy":"2023-04-17T10:14:45.148974Z","iopub.execute_input":"2023-04-17T10:14:45.149716Z","iopub.status.idle":"2023-04-17T10:14:45.470448Z","shell.execute_reply.started":"2023-04-17T10:14:45.149647Z","shell.execute_reply":"2023-04-17T10:14:45.469209Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"valid_dataset = SquadDataset(valid_df, 16)","metadata":{"id":"SgEJ4TWiXFkF","execution":{"iopub.status.busy":"2023-04-17T10:14:45.472038Z","iopub.execute_input":"2023-04-17T10:14:45.472802Z","iopub.status.idle":"2023-04-17T10:14:45.601328Z","shell.execute_reply.started":"2023-04-17T10:14:45.472755Z","shell.execute_reply":"2023-04-17T10:14:45.600218Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## BiDAF Model","metadata":{"id":"j2NM5xbYXFkG"}},{"cell_type":"markdown","source":"## Word Embedding","metadata":{"id":"W2oDfA_mXFkG"}},{"cell_type":"code","source":"# Loading the weights to load in future\n\nweights_matrix = np.load('/kaggle/input/loadbidaf/bidafglove_tv.npy')","metadata":{"id":"5rbx3XUzXFkI","execution":{"iopub.status.busy":"2023-04-17T10:14:45.603084Z","iopub.execute_input":"2023-04-17T10:14:45.603493Z","iopub.status.idle":"2023-04-17T10:14:46.691145Z","shell.execute_reply.started":"2023-04-17T10:14:45.603456Z","shell.execute_reply":"2023-04-17T10:14:46.689879Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Character Embedding","metadata":{"id":"g4rf3V-dXFkI"}},{"cell_type":"code","source":"class CharacterEmbeddingLayer(nn.Module):\n    \n    def __init__(self, char_vocab_dim, char_emb_dim, num_output_channels, kernel_size):\n        \n        super().__init__()\n        \n        self.char_emb_dim = char_emb_dim\n        \n        self.char_embedding = nn.Embedding(char_vocab_dim, char_emb_dim, padding_idx=1)\n        \n        self.char_convolution = nn.Conv2d(in_channels=1, out_channels=num_output_channels, kernel_size=kernel_size)\n        \n        self.relu = nn.ReLU()\n    \n        self.dropout = nn.Dropout(DROPOUT_RATE)\n                \n    def forward(self, x):\n        # x = [bs, seq_len, word_len]\n        # returns : [batch_size, seq_len, num_output_channels]\n        # the output can be thought of as another feature embedding of dim 100.\n        \n        batch_size = x.shape[0] \n        \n        x = self.dropout(self.char_embedding(x))\n        # x = [bs, seq_len, word_len, char_emb_dim]\n        \n        # following three operations manipulate x in such a way that\n        # it closely resembles an image. this format is important before \n        # we perform convolution on the character embeddings.\n        \n        x = x.permute(0,1,3,2)\n        # x = [bs, seq_len, char_emb_dim, word_len]\n        \n        x = x.view(-1, self.char_emb_dim, x.shape[3])\n        # x = [bs*seq_len, char_emb_dim, word_len]\n        \n        x = x.unsqueeze(1)\n        # x = [bs*seq_len, 1, char_emb_dim, word_len]\n        \n        # x is now in a format that can be accepted by a conv layer. \n        # think of the tensor above in terms of an image of dimension\n        # (N, C_in, H_in, W_in).\n        \n        x = self.relu(self.char_convolution(x))\n        # x = [bs*seq_len, out_channels, H_out, W_out]\n        \n        x = x.squeeze()\n        # x = [bs*seq_len, out_channels, W_out]\n             \n        x = F.max_pool1d(x, x.shape[2]).squeeze()\n        # x = [bs*seq_len, out_channels, 1] => [bs*seq_len, out_channels]\n        \n        x = x.view(batch_size, -1, x.shape[-1])\n        # x = [bs, seq_len, out_channels]\n        # x = [bs, seq_len, features] = [bs, seq_len, 100]\n        \n        \n        return x        ","metadata":{"id":"qULa_r5UXFkI","execution":{"iopub.status.busy":"2023-04-17T10:14:46.696850Z","iopub.execute_input":"2023-04-17T10:14:46.699428Z","iopub.status.idle":"2023-04-17T10:14:46.817550Z","shell.execute_reply.started":"2023-04-17T10:14:46.699388Z","shell.execute_reply":"2023-04-17T10:14:46.816511Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Highway Networks","metadata":{"id":"h_dHCV4NXFkJ"}},{"cell_type":"code","source":"class HighwayNetwork(nn.Module):\n    \n    def __init__(self, input_dim, num_layers=2):\n        \n        super().__init__()\n        \n        self.num_layers = num_layers\n        \n        self.flow_layer = nn.ModuleList([nn.Linear(input_dim, input_dim) for _ in range(num_layers)])\n        self.gate_layer = nn.ModuleList([nn.Linear(input_dim, input_dim) for _ in range(num_layers)])\n        \n    def forward(self, x):\n        \n        for i in range(self.num_layers):\n            \n            flow_value = F.relu(self.flow_layer[i](x))\n            gate_value = torch.sigmoid(self.gate_layer[i](x))\n            \n            x = gate_value * flow_value + (1-gate_value) * x\n        \n        return x","metadata":{"id":"51uYJKaAXFkJ","execution":{"iopub.status.busy":"2023-04-17T10:14:46.825832Z","iopub.execute_input":"2023-04-17T10:14:46.829448Z","iopub.status.idle":"2023-04-17T10:14:46.938093Z","shell.execute_reply.started":"2023-04-17T10:14:46.829409Z","shell.execute_reply":"2023-04-17T10:14:46.936957Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Contextual Embedding","metadata":{"id":"FjuEeTMsXFkJ"}},{"cell_type":"code","source":"class ContextualEmbeddingLayer(nn.Module):\n    \n    def __init__(self, input_dim, hidden_dim):\n        \n        super().__init__()\n        \n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n        \n        self.highway_net = HighwayNetwork(input_dim)\n        \n    def forward(self, x):\n        # x = [bs, seq_len, input_dim] = [bs, seq_len, emb_dim*2]\n        # the input is the concatenation of word and characeter embeddings\n        # for the sequence.\n        \n        highway_out = self.highway_net(x)\n        # highway_out = [bs, seq_len, input_dim]\n        \n        outputs, _ = self.lstm(highway_out)\n        # outputs = [bs, seq_len, emb_dim*2]\n        \n        return outputs","metadata":{"id":"qSVQlRlZXFkJ","execution":{"iopub.status.busy":"2023-04-17T10:14:46.943568Z","iopub.execute_input":"2023-04-17T10:14:46.946310Z","iopub.status.idle":"2023-04-17T10:14:47.053738Z","shell.execute_reply.started":"2023-04-17T10:14:46.946268Z","shell.execute_reply":"2023-04-17T10:14:47.052552Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Attention Flow Layer","metadata":{"id":"b6e0g0WVXFkK","tags":[]}},{"cell_type":"code","source":"class BiDAF(nn.Module):\n    \n    def __init__(self, char_vocab_dim, emb_dim, char_emb_dim, num_output_channels, \n                 kernel_size, ctx_hidden_dim, device):\n        '''\n        char_vocab_dim = len(char2idx)\n        emb_dim = 100\n        char_emb_dim = 8\n        num_output_chanels = 100\n        kernel_size = (8,5)\n        ctx_hidden_dim = 100\n        '''\n        super().__init__()\n        \n        self.device = device\n        \n        self.word_embedding = self.get_glove_embedding()\n        \n        self.character_embedding = CharacterEmbeddingLayer(char_vocab_dim, char_emb_dim, \n                                                      num_output_channels, kernel_size)\n        \n        self.contextual_embedding = ContextualEmbeddingLayer(emb_dim*2, ctx_hidden_dim)\n        \n        self.dropout = nn.Dropout()\n        \n        self.similarity_weight = nn.Linear(emb_dim*6, 1, bias=False)\n        \n        self.modeling_lstm = nn.LSTM(emb_dim*8, emb_dim, bidirectional=True, num_layers=2, batch_first=True, dropout=0.2)\n        \n        self.output_start = nn.Linear(emb_dim*10, 1, bias=False)\n        \n        self.output_end = nn.Linear(emb_dim*10, 1, bias=False)\n        \n        self.end_lstm = nn.LSTM(emb_dim*2, emb_dim, bidirectional=True, batch_first=True)\n        \n    \n    def get_glove_embedding(self):\n        \n        weights_matrix = np.load('/kaggle/input/loadbidaf/bidafglove_tv.npy')\n        num_embeddings, embedding_dim = weights_matrix.shape\n        embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights_matrix).to(self.device),freeze=True)\n\n        return embedding\n        \n    def forward(self, ctx, ques, char_ctx, char_ques):\n        # ctx = [bs, ctx_len]\n        # ques = [bs, ques_len]\n        # char_ctx = [bs, ctx_len, ctx_word_len]\n        # char_ques = [bs, ques_len, ques_word_len]\n        \n        ctx_len = ctx.shape[1]\n        \n        ques_len = ques.shape[1]\n        \n        ## GET WORD AND CHARACTER EMBEDDINGS\n        \n        ctx_word_embed = self.word_embedding(ctx)\n        # ctx_word_embed = [bs, ctx_len, emb_dim]\n        \n        ques_word_embed = self.word_embedding(ques)\n        # ques_word_embed = [bs, ques_len, emb_dim]\n        \n        ctx_char_embed = self.character_embedding(char_ctx)\n        # ctx_char_embed =  [bs, ctx_len, emb_dim]\n        \n        ques_char_embed = self.character_embedding(char_ques)\n        # ques_char_embed = [bs, ques_len, emb_dim]\n        \n        ## CREATE CONTEXTUAL EMBEDDING\n        \n        ctx_contextual_inp = torch.cat([ctx_word_embed, ctx_char_embed],dim=2)\n        # [bs, ctx_len, emb_dim*2]\n        \n        ques_contextual_inp = torch.cat([ques_word_embed, ques_char_embed],dim=2)\n        # [bs, ques_len, emb_dim*2]\n        \n        ctx_contextual_emb = self.contextual_embedding(ctx_contextual_inp)\n        # [bs, ctx_len, emb_dim*2]\n        \n        ques_contextual_emb = self.contextual_embedding(ques_contextual_inp)\n        # [bs, ques_len, emb_dim*2]\n        \n        \n        ## CREATE SIMILARITY MATRIX\n        \n        ctx_ = ctx_contextual_emb.unsqueeze(2).repeat(1,1,ques_len,1)\n        # [bs, ctx_len, 1, emb_dim*2] => [bs, ctx_len, ques_len, emb_dim*2]\n        \n        ques_ = ques_contextual_emb.unsqueeze(1).repeat(1,ctx_len,1,1)\n        # [bs, 1, ques_len, emb_dim*2] => [bs, ctx_len, ques_len, emb_dim*2]\n        \n        elementwise_prod = torch.mul(ctx_, ques_)\n        # [bs, ctx_len, ques_len, emb_dim*2]\n        \n        alpha = torch.cat([ctx_, ques_, elementwise_prod], dim=3)\n        # [bs, ctx_len, ques_len, emb_dim*6]\n        \n        similarity_matrix = self.similarity_weight(alpha).view(-1, ctx_len, ques_len)\n        # [bs, ctx_len, ques_len]\n        \n        \n        ## CALCULATE CONTEXT2QUERY ATTENTION\n        \n        a = F.softmax(similarity_matrix, dim=-1)\n        # [bs, ctx_len, ques_len]\n        \n        c2q = torch.bmm(a, ques_contextual_emb)\n        # [bs] ([ctx_len, ques_len] X [ques_len, emb_dim*2]) => [bs, ctx_len, emb_dim*2]\n        \n        \n        ## CALCULATE QUERY2CONTEXT ATTENTION\n        \n        b = F.softmax(torch.max(similarity_matrix,2)[0], dim=-1)\n        # [bs, ctx_len]\n        \n        b = b.unsqueeze(1)\n        # [bs, 1, ctx_len]\n        \n        q2c = torch.bmm(b, ctx_contextual_emb)\n        # [bs] ([bs, 1, ctx_len] X [bs, ctx_len, emb_dim*2]) => [bs, 1, emb_dim*2]\n        \n        q2c = q2c.repeat(1, ctx_len, 1)\n        # [bs, ctx_len, emb_dim*2]\n        \n        ## QUERY AWARE REPRESENTATION\n        \n        G = torch.cat([ctx_contextual_emb, c2q, \n                       torch.mul(ctx_contextual_emb,c2q), \n                       torch.mul(ctx_contextual_emb, q2c)], dim=2)\n        \n        # [bs, ctx_len, emb_dim*8]\n        \n        \n        ## MODELING LAYER\n        \n        M, _ = self.modeling_lstm(G)\n        # [bs, ctx_len, emb_dim*2]\n        \n        ## OUTPUT LAYER\n        \n        M2, _ = self.end_lstm(M)\n        \n        # START PREDICTION\n        \n        p1 = self.output_start(torch.cat([G,M], dim=2))\n        # [bs, ctx_len, 1]\n        \n        p1 = p1.squeeze()\n        # [bs, ctx_len]\n        \n        #p1 = F.softmax(p1, dim=-1)\n        \n        # END PREDICTION\n        \n        p2 = self.output_end(torch.cat([G, M2], dim=2)).squeeze()\n        # [bs, ctx_len, 1] => [bs, ctx_len]\n        \n        #p2 = F.softmax(p2, dim=-1)\n        \n        \n        return p1, p2\n    ","metadata":{"id":"8pwrHBFiXFkL","execution":{"iopub.status.busy":"2023-04-17T10:14:47.058652Z","iopub.execute_input":"2023-04-17T10:14:47.061276Z","iopub.status.idle":"2023-04-17T10:14:47.186401Z","shell.execute_reply.started":"2023-04-17T10:14:47.061238Z","shell.execute_reply":"2023-04-17T10:14:47.185512Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"Fa1RTj5AXFkM"}},{"cell_type":"code","source":"HIDDEN_SIZE = 100\nCHARACTER_CHANNEL_WIDTH = 5\nDROPOUT_RATE = 0.2\nCHAR_VOCAB_DIM = len(char2idx)\nEMB_DIM = HIDDEN_SIZE # need to match up with hidden size\nCHAR_EMB_DIM = 8\nNUM_OUTPUT_CHANNELS = HIDDEN_SIZE # need to match up with hidden size\nKERNEL_SIZE = (8,CHARACTER_CHANNEL_WIDTH)\ndevice = torch.device('cuda')\n\nmodel = BiDAF(CHAR_VOCAB_DIM, \n              EMB_DIM, \n              CHAR_EMB_DIM, \n              NUM_OUTPUT_CHANNELS, \n              KERNEL_SIZE, \n              HIDDEN_SIZE, \n              device).to(device)","metadata":{"id":"3BNSWRXBXFkM","execution":{"iopub.status.busy":"2023-04-17T10:14:47.191403Z","iopub.execute_input":"2023-04-17T10:14:47.194147Z","iopub.status.idle":"2023-04-17T10:14:49.689137Z","shell.execute_reply.started":"2023-04-17T10:14:47.194108Z","shell.execute_reply":"2023-04-17T10:14:49.687904Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.autograd import Variable","metadata":{"id":"-e7eiLTKXFkM","execution":{"iopub.status.busy":"2023-04-17T10:14:49.690822Z","iopub.execute_input":"2023-04-17T10:14:49.691558Z","iopub.status.idle":"2023-04-17T10:14:49.770406Z","shell.execute_reply.started":"2023-04-17T10:14:49.691515Z","shell.execute_reply":"2023-04-17T10:14:49.769118Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def valid_validDataset(model, valid_dataset):\n    \n    print(\"Starting validation .........\")\n   \n    valid_loss = 0.\n\n    batch_count = 0\n    \n    f1, em = 0., 0.\n    \n    model.eval()\n        \n   \n    predictions = {}\n    \n    for batch in valid_dataset:\n\n        if batch_count % 500 == 0:\n            print(f\"Starting batch {batch_count}\")\n        batch_count += 1\n\n        context, question, char_ctx, char_ques, label, ctx, answers, ids = batch\n        context, question, char_ctx, char_ques, label = context.to(device), question.to(device),\\\n                                   char_ctx.to(device), char_ques.to(device), label.to(device)\n        \n        with torch.no_grad():\n            \n            s_idx, e_idx = label[:,0], label[:,1]\n\n            preds = model(context, question, char_ctx, char_ques)\n\n            p1, p2 = preds\n\n            loss = F.cross_entropy(p1, s_idx) + F.cross_entropy(p2, e_idx)\n\n            valid_loss += loss.item()\n\n            batch_size, c_len = p1.size()\n            ls = nn.LogSoftmax(dim=1)\n            mask = (torch.ones(c_len, c_len) * float('-inf')).to(device).tril(-1).unsqueeze(0).expand(batch_size, -1, -1)\n            score = (ls(p1).unsqueeze(2) + ls(p2).unsqueeze(1)) + mask\n            score, s_idx = score.max(dim=1)\n            score, e_idx = score.max(dim=1)\n            s_idx = torch.gather(s_idx, 1, e_idx.view(-1, 1)).squeeze()\n            \n            for i in range(batch_size):\n                id = ids[i]\n                pred = context[i][s_idx[i]:e_idx[i]+1]\n                pred = ' '.join([idx2word[idx.item()] for idx in pred])\n                predictions[id] = pred\n                \n#     print(predictions)\n    prediction_validDataset_BIDAF = 'prediction_validDataset_BIDAF.txt'\n    with open(prediction_validDataset_BIDAF, 'w', encoding='utf-8') as file:\n        json.dump(predictions, file, ensure_ascii=False)\n    new_predictions, em, f1 = evaluate_validDataset(predictions)\n    return valid_loss/len(valid_dataset), em, f1\n\n\ndef valid_trainDataset(model, train_dataset):\n    \n    print(\"Starting validation .........\")\n   \n    train_loss = 0.\n\n    batch_count = 0\n    \n    f1, em = 0., 0.\n    \n    model.eval()\n        \n    predictions = {}\n    \n    for batch in train_dataset:\n\n        if batch_count % 500 == 0:\n            print(f\"Starting batch {batch_count}\")\n        batch_count += 1\n\n        context, question, char_ctx, char_ques, label, ctx, answers, ids = batch\n        context, question, char_ctx, char_ques, label = context.to(device), question.to(device),\\\n                                   char_ctx.to(device), char_ques.to(device), label.to(device)\n        \n        with torch.no_grad():\n            \n            s_idx, e_idx = label[:,0], label[:,1]\n\n            preds = model(context, question, char_ctx, char_ques)\n\n            p1, p2 = preds\n\n            loss = F.cross_entropy(p1, s_idx) + F.cross_entropy(p2, e_idx)\n\n            train_loss += loss.item()\n\n            batch_size, c_len = p1.size()\n            ls = nn.LogSoftmax(dim=1)\n            mask = (torch.ones(c_len, c_len) * float('-inf')).to(device).tril(-1).unsqueeze(0).expand(batch_size, -1, -1)\n            score = (ls(p1).unsqueeze(2) + ls(p2).unsqueeze(1)) + mask\n            score, s_idx = score.max(dim=1)\n            score, e_idx = score.max(dim=1)\n            s_idx = torch.gather(s_idx, 1, e_idx.view(-1, 1)).squeeze()\n            \n            for i in range(batch_size):\n                id = ids[i]\n                pred = context[i][s_idx[i]:e_idx[i]+1]\n                pred = ' '.join([idx2word[idx.item()] for idx in pred])\n                predictions[id] = pred\n                \n#     print(predictions)\n    prediction_trainDataset_BIDAF = 'prediction_trainDataset_BIDAF.txt'\n\n    new_predictions, em, f1 = evaluate_trainDataset(predictions)\n    with open(prediction_trainDataset_BIDAF, 'w', encoding='utf-8') as file:\n        json.dump(new_predictions, file, ensure_ascii=False)\n        \n    return train_loss/len(train_dataset), em, f1","metadata":{"id":"zEJCdFpJXFkN","execution":{"iopub.status.busy":"2023-04-17T10:47:18.440863Z","iopub.execute_input":"2023-04-17T10:47:18.441291Z","iopub.status.idle":"2023-04-17T10:47:18.535300Z","shell.execute_reply.started":"2023-04-17T10:47:18.441255Z","shell.execute_reply":"2023-04-17T10:47:18.534204Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def evaluate_validDataset(predictions):\n    '''\n    Gets a dictionary of predictions with question_id as key\n    and prediction as value. The validation dataset has multiple \n    answers for a single question. Hence we compare our prediction\n    with all the answers and choose the one that gives us\n    the maximum metric (em or f1). \n    This method first parses the JSON file, gets all the answers\n    for a given id and then passes the list of answers and the \n    predictions to calculate em, f1.\n    \n    \n    :param dict predictions\n    Returns\n    : exact_match: 1 if the prediction and ground truth \n      match exactly, 0 otherwise.\n    : f1_score: \n    '''\n    with open('/kaggle/input/new-squaddataset/dev-v2.0.json','r',encoding='utf-8') as f:\n        dataset = json.load(f)\n    new_predictions = {}\n    dataset = dataset['data']\n    f1 = exact_match = total = 0\n    for article in dataset:\n        for paragraph in article['paragraphs']:\n            for qa in paragraph['qas']:\n                total += 1\n                if qa['id'] not in predictions:\n                    continue\n                \n                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n                \n                prediction = predictions[qa['id']]\n\n                exact_match += metric_max_over_ground_truths(\n                    exact_match_score, prediction, ground_truths)\n\n                curr_f1 = metric_max_over_ground_truths(\n                    f1_score, prediction, ground_truths)\n                \n                new_predictions[qa['id']] = [prediction, curr_f1]\n                f1 += curr_f1\n                \n    \n    exact_match = 100.0 * exact_match / total\n    f1 = 100.0 * f1 / total\n    \n    return new_predictions, exact_match, f1\n\n\ndef evaluate_trainDataset(predictions):\n    '''\n    Gets a dictionary of predictions with question_id as key\n    and prediction as value. The validation dataset has multiple \n    answers for a single question. Hence we compare our prediction\n    with all the answers and choose the one that gives us\n    the maximum metric (em or f1). \n    This method first parses the JSON file, gets all the answers\n    for a given id and then passes the list of answers and the \n    predictions to calculate em, f1.\n    \n    \n    :param dict predictions\n    Returns\n    : exact_match: 1 if the prediction and ground truth \n      match exactly, 0 otherwise.\n    : f1_score: \n    '''\n    new_predictions = {}\n    with open('/kaggle/input/new-squaddataset/train-v2.0.json','r',encoding='utf-8') as f:\n        dataset = json.load(f)\n        \n    dataset = dataset['data']\n    f1 = exact_match = total = 0\n    for article in dataset:\n        for paragraph in article['paragraphs']:\n            for qa in paragraph['qas']:\n                total += 1\n                if qa['id'] not in predictions:\n                    continue\n                \n                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n                \n                prediction = predictions[qa['id']]\n                \n                exact_match += metric_max_over_ground_truths(\n                    exact_match_score, prediction, ground_truths)\n                \n                curr_f1 = metric_max_over_ground_truths(\n                    f1_score, prediction, ground_truths)\n                \n                new_predictions[qa['id']] = [prediction, curr_f1]\n                f1 += curr_f1\n                \n    \n    exact_match = 100.0 * exact_match / total\n    f1 = 100.0 * f1 / total\n    \n    return new_predictions, exact_match, f1\n\n","metadata":{"id":"NgNHepmzXFkN","execution":{"iopub.status.busy":"2023-04-17T18:42:40.794077Z","iopub.execute_input":"2023-04-17T18:42:40.794738Z","iopub.status.idle":"2023-04-17T18:42:40.809880Z","shell.execute_reply.started":"2023-04-17T18:42:40.794691Z","shell.execute_reply":"2023-04-17T18:42:40.808558Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def normalize_answer(s):\n    '''\n    Performs a series of cleaning steps on the ground truth and \n    predicted answer.\n    '''\n    def remove_articles(text):\n        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n\n    def white_space_fix(text):\n        return ' '.join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return ''.join(ch for ch in text if ch not in exclude)\n\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\n\ndef metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n    '''\n    Returns maximum value of metrics for predicition by model against\n    multiple ground truths.\n    \n    :param func metric_fn: can be 'exact_match_score' or 'f1_score'\n    :param str prediction: predicted answer span by the model\n    :param list ground_truths: list of ground truths against which\n                               metrics are calculated. Maximum values of \n                               metrics are chosen.\n                            \n    \n    '''\n    scores_for_ground_truths = []\n    for ground_truth in ground_truths:\n        score = metric_fn(prediction, ground_truth)\n        scores_for_ground_truths.append(score)\n        \n    return max(scores_for_ground_truths)\n\n\ndef f1_score(prediction, ground_truth):\n    '''\n    Returns f1 score of two strings.\n    '''\n    prediction_tokens = normalize_answer(prediction).split()\n    ground_truth_tokens = normalize_answer(ground_truth).split()\n    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n    num_same = sum(common.values())\n    if num_same == 0:\n        return 0\n    precision = 1.0 * num_same / len(prediction_tokens)\n    recall = 1.0 * num_same / len(ground_truth_tokens)\n    f1 = (2 * precision * recall) / (precision + recall)\n    return f1\n\n\ndef exact_match_score(prediction, ground_truth):\n    '''\n    Returns exact_match_score of two strings.\n    '''\n    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n\n\ndef epoch_time(start_time, end_time):\n    '''\n    Helper function to record epoch time.\n    '''\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"id":"D4HzBoeOXFkO","execution":{"iopub.status.busy":"2023-04-17T18:42:55.165539Z","iopub.execute_input":"2023-04-17T18:42:55.166005Z","iopub.status.idle":"2023-04-17T18:42:55.179147Z","shell.execute_reply.started":"2023-04-17T18:42:55.165968Z","shell.execute_reply":"2023-04-17T18:42:55.177927Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"LEARNING_RATE = 0.5\noptimizer=optim.Adam(model.parameters(), lr=LEARNING_RATE)\nsave_location = \"/kaggle/input/savedbidafmodel/AdaDelta_halved.pth\"\ncheckpoint = torch.load(save_location)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2023-04-17T10:47:19.629146Z","iopub.execute_input":"2023-04-17T10:47:19.629512Z","iopub.status.idle":"2023-04-17T10:47:19.770891Z","shell.execute_reply.started":"2023-04-17T10:47:19.629479Z","shell.execute_reply":"2023-04-17T10:47:19.769857Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import json","metadata":{"execution":{"iopub.status.busy":"2023-04-17T10:47:19.913951Z","iopub.execute_input":"2023-04-17T10:47:19.914289Z","iopub.status.idle":"2023-04-17T10:47:19.992640Z","shell.execute_reply.started":"2023-04-17T10:47:19.914259Z","shell.execute_reply":"2023-04-17T10:47:19.991722Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"train_losses = []\nvalid_losses = []\nepochs = 1\nbest_valid_loss=99999\n\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch+1}\")\n    start_time = time.time()\n    \n    train_loss, em_train, f1_train = valid_trainDataset(model, train_dataset)\n    valid_loss, em_valid, f1_valid = valid_validDataset(model, valid_dataset)\n    \n    end_time = time.time()\n    \n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n\n    print(f\"Epoch valid loss: {train_loss}\")\n    print(f\"Epoch train Dataset EM: {em_train}\")\n    print(f\"Epoch train Dataset F1: {f1_train}\")\n    \n    print(f\"Epoch valid loss: {valid_loss}\")\n    print(f\"Epoch train Dataset EM: {em_valid}\")\n    print(f\"Epoch train Dataset F1: {f1_valid}\")\n    print(\"====================================================================================\")\n    ","metadata":{"id":"cEGSVxESXFkO","outputId":"8ad76c2e-f840-4e26-e253-3ce3b37563f4","execution":{"iopub.status.busy":"2023-04-17T10:47:20.313850Z","iopub.execute_input":"2023-04-17T10:47:20.314157Z","iopub.status.idle":"2023-04-17T11:01:25.198019Z","shell.execute_reply.started":"2023-04-17T10:47:20.314128Z","shell.execute_reply":"2023-04-17T11:01:25.196808Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1\nStarting validation .........\nStarting batch 0\nStarting batch 500\nStarting batch 1000\nStarting batch 1500\nStarting batch 2000\nStarting batch 2500\nStarting batch 3000\nStarting batch 3500\nStarting batch 4000\nStarting batch 4500\nStarting batch 5000\nStarting batch 5500\nStarting batch 6000\nStarting batch 6500\nStarting batch 7000\nStarting batch 7500\nStarting batch 8000\nStarting batch 8500\nStarting batch 9000\nStarting batch 9500\nStarting batch 10000\nStarting batch 10500\nStarting validation .........\nStarting batch 0\nStarting batch 500\nStarting batch 1000\nStarting batch 1500\nStarting batch 2000\nEpoch valid loss: 3.1443854363484762\nEpoch train Dataset EM: 49.47430906745511\nEpoch train Dataset F1: 64.46439386071377\nEpoch valid loss: 3.7826525786620286\nEpoch train Dataset EM: 53.964049195837276\nEpoch train Dataset F1: 65.91183413481801\n====================================================================================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Visualizing Performance of different models","metadata":{}},{"cell_type":"markdown","source":"Note: there were no test dataset, only validation dataset was there. All the performance on the table was that after 3 epochs.","metadata":{}},{"cell_type":"code","source":"from tabulate import tabulate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device('cuda')\noverall_result = []\nconfig_names=['AdaDelta_default','AdaDelta_default','AdaDelta_halved','Adam_default', 'SGD_default',\n              'dropout-.15','dropout-.25','charwidth4','hidden50']\n\nfor i, _ in enumerate(config_names):\n    indiv_result = []\n    save_location =  f\"/kaggle/input/savedbidafmodel/{config_names[i]}.pth\"\n    checkpoint = torch.load(save_location)\n    valid_loss=checkpoint['loss']\n    em=checkpoint['em']  \n    f1=checkpoint['f1']\n\n    indiv_result.append(config_names[i])\n    indiv_result.append(valid_loss)\n    indiv_result.append(em)\n    indiv_result.append(f1)\n    overall_result.append(indiv_result)\n\nprint(tabulate(overall_result, headers=['Model', 'Valid Loss', 'EM', 'F1']))","metadata":{"id":"b8atlRxvXFkO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References\n* Papers read/referred:\n    1. BiDAF: https://arxiv.org/abs/1611.01603\n    2. Convolutional Neural Networks for Sentence Classification: https://arxiv.org/abs/1408.5882\n    3. Highway Networks: https://arxiv.org/abs/1505.00387\n* Other helpful links:\n    1. https://nlp.seas.harvard.edu/slides/aaai16.pdf. A great resource for character embeddings. The figures in the character embedding section are taken from here.\n    2. https://towardsdatascience.com/the-definitive-guide-to-bi-directional-attention-flow-d0e96e9e666b. A great series of blogs to understand BiDAF.\n    Some of the following repos might be out of date.\n    3. https://github.com/allenai/bi-att-flow\n    4. https://github.com/galsang\n    5. https://github.com/jojonki/BiDAF/","metadata":{"id":"gVgPQ3w7XFkO"}}]}